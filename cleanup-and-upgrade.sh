#!/bin/bash

echo "=========================================="
echo "ANKR LLM STACK OPTIMIZATION"
echo "=========================================="
echo ""

echo "ðŸ“Š BEFORE:"
docker exec mari8x-ollama ollama list
echo ""

echo "ðŸ—‘ï¸  Step 1: Remove redundant models..."
docker exec mari8x-ollama ollama rm captain-llm 2>/dev/null && echo "  âœ… Removed captain-llm" || echo "  âš ï¸  Already removed"
docker exec mari8x-ollama ollama rm llama3.1:8b 2>/dev/null && echo "  âœ… Removed llama3.1:8b" || echo "  âš ï¸  Already removed"
docker exec mari8x-ollama ollama rm captain-llm-v2 2>/dev/null && echo "  âœ… Removed captain-llm-v2" || echo "  âš ï¸  Already removed"
echo ""

echo "â¬†ï¸  Step 2: Upgrade embeddings to v2..."
docker exec mari8x-ollama ollama pull nomic-embed-text-v2
echo "  âœ… Pulled nomic-embed-text-v2"
docker exec mari8x-ollama ollama rm nomic-embed-text 2>/dev/null && echo "  âœ… Removed old nomic-embed-text v1" || true
echo ""

echo "ðŸš€ Step 3: Add fast code model (optional)..."
docker exec mari8x-ollama ollama pull qwen2.5-coder:1.5b
echo "  âœ… Added qwen2.5-coder:1.5b (specialized for code)"
echo ""

echo "ðŸ“Š AFTER:"
docker exec mari8x-ollama ollama list
echo ""

echo "=========================================="
echo "âœ… OPTIMIZATION COMPLETE!"
echo ""
echo "Final Setup:"
echo "  â€¢ nomic-embed-text-v2 (embeddings, 0.3GB)"
echo "  â€¢ qwen2.5:1.5b (general, 1GB)"
echo "  â€¢ qwen2.5-coder:1.5b (code, 1GB)"
echo ""
echo "Total: ~2.3GB (saved 11.2GB!)"
echo ""
echo "Next Steps:"
echo "  1. Get free API keys:"
echo "     - https://platform.deepseek.com"
echo "     - https://console.groq.com/keys"
echo ""
echo "  2. Configure SLM Router:"
echo "     cd /root/ankr-labs-nx/packages/ankr-slm-router"
echo "     cp .env.example .env"
echo "     # Add your API keys to .env"
echo ""
echo "  3. Test:"
echo "     npx tsx src/clients/test-connectivity.ts"
echo "=========================================="
